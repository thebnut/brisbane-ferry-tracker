/**
 * Train Schedule API Processor - VERSION 6.0
 *
 * TWO-TIERED DATA MODEL: Optimized for departure boards + lazy-loaded trip details
 *
 * TIER 1: Station Schedule Files (train-station-{ORIGIN}.json)
 * - Lightweight departure board data
 * - Trips with patternId references + compact stopTimes arrays
 * - ~70-80% smaller than v5
 *
 * TIER 2: Trip Pattern Files (train-pattern-{PATTERN_ID}.json)
 * - Detailed intermediate stop sequences
 * - Lazy-loaded when user clicks trip for details
 * - Shared across multiple trips (eliminates duplication)
 *
 * Key improvements over v5:
 * 1. Separated trip patterns from trip instances
 * 2. Reduced file sizes by 70-80% (7.3GB ‚Üí ~605MB)
 * 3. Faster API responses (59KB ‚Üí ~13KB for departure board)
 * 4. Better caching (patterns cached 24 hours vs schedules 5 minutes)
 * 5. Optimized for mobile bandwidth
 *
 * Usage: node process-schedule-api-station-v6.js
 */

import JSZip from 'jszip';
import Papa from 'papaparse';
import { format, parse, addDays, startOfDay } from 'date-fns';
import { toZonedTime } from 'date-fns-tz';
import { put, del, list } from '@vercel/blob';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import crypto from 'crypto';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

// Configuration
const MODE = 'train';
const ROUTE_TYPE = 2; // GTFS route type for trains
const TIMEZONE = 'Australia/Brisbane';
const GTFS_URL = 'https://gtfsrt.api.translink.com.au/GTFS/SEQ_GTFS.zip';
const DAYS_TO_PROCESS = 7; // Process next 7 days

/**
 * Build platform-to-station mapping from grouped stations file
 */
async function buildStationMappings() {
  try {
    const groupedData = JSON.parse(
      await fs.readFile(path.join(__dirname, 'train-stations-grouped.json'), 'utf-8')
    );

    const platformToStation = new Map(); // platform ID -> station name
    const stationSlugs = new Map(); // station name -> URL-safe slug
    const stationPlatforms = new Map(); // station name -> array of platform IDs
    const stationCoords = new Map(); // station name -> { lat, lng }

    groupedData.stations.forEach(station => {
      const stationName = station.name;

      // Create URL-safe slug (match v4 logic exactly)
      const slug = stationName
        .replace(/\s+station$/i, '')
        .trim()
        .toUpperCase()
        .replace(/[^A-Z0-9]+/g, '_')
        .replace(/^_|_$/g, '');

      stationSlugs.set(stationName, slug);
      stationPlatforms.set(stationName, station.stopIds);

      // Map each platform ID to this station
      station.stopIds.forEach(platformId => {
        platformToStation.set(platformId, stationName);
      });
    });

    console.log(`‚úÖ Built mappings for ${stationSlugs.size} stations, ${platformToStation.size} platforms`);

    return { platformToStation, stationSlugs, stationPlatforms, stationCoords };
  } catch (error) {
    console.error('‚ùå Error building station mappings:', error);
    throw error;
  }
}

/**
 * Download GTFS data
 */
async function downloadGTFS() {
  console.log('üì• Downloading GTFS data from TransLink...');

  const response = await fetch(GTFS_URL);
  if (!response.ok) {
    throw new Error(`Failed to download GTFS: ${response.statusText}`);
  }

  const buffer = await response.arrayBuffer();
  console.log(`‚úÖ Downloaded ${(buffer.byteLength / (1024 * 1024)).toFixed(2)} MB`);

  return buffer;
}

/**
 * Parse GTFS ZIP file
 */
async function parseGTFSFiles(buffer) {
  console.log('üì¶ Extracting GTFS files...');

  const zip = await JSZip.loadAsync(buffer);
  const gtfsData = {};

  const filesToParse = ['stops.txt', 'routes.txt', 'trips.txt', 'stop_times.txt', 'calendar.txt', 'calendar_dates.txt'];

  for (const filename of filesToParse) {
    const file = zip.file(filename);
    if (!file) {
      console.warn(`‚ö†Ô∏è  ${filename} not found in GTFS`);
      continue;
    }

    const text = await file.async('text');
    const parsed = Papa.parse(text, { header: true, skipEmptyLines: true });
    gtfsData[filename] = parsed.data;
    console.log(`  ‚úì ${filename}: ${parsed.data.length} records`);
  }

  return gtfsData;
}

/**
 * Filter GTFS data for trains only
 */
function filterTrainData(gtfsData) {
  console.log('üöÇ Filtering train data...');

  const trainRoutes = gtfsData['routes.txt'].filter(
    route => route.route_type === String(ROUTE_TYPE)
  );

  const trainRouteIds = new Set(trainRoutes.map(r => r.route_id));

  const trainTrips = gtfsData['trips.txt'].filter(
    trip => trainRouteIds.has(trip.route_id)
  );

  const trainTripIds = new Set(trainTrips.map(t => t.trip_id));
  const trainStopTimes = gtfsData['stop_times.txt'].filter(
    st => trainTripIds.has(st.trip_id)
  );

  console.log(`‚úÖ Filtered ${trainRoutes.length} routes, ${trainTrips.length} trips, ${trainStopTimes.length} stop_times`);

  return {
    routes: trainRoutes,
    trips: trainTrips,
    stopTimes: trainStopTimes,
    stops: gtfsData['stops.txt'],
    calendar: gtfsData['calendar.txt'],
    calendarDates: gtfsData['calendar_dates.txt']
  };
}

/**
 * Get active service IDs for date range
 */
function getActiveServices(calendar, calendarDates, startDate, endDate) {
  const servicesByDate = new Map();

  let currentDate = new Date(startDate);
  while (currentDate <= endDate) {
    const dayOfWeek = format(currentDate, 'EEEE').toLowerCase();
    const dateStr = format(currentDate, 'yyyyMMdd');
    const activeServices = new Set();

    // Check regular calendar
    calendar.forEach(service => {
      const serviceStart = parse(service.start_date, 'yyyyMMdd', new Date());
      const serviceEnd = parse(service.end_date, 'yyyyMMdd', new Date());

      if (currentDate >= serviceStart && currentDate <= serviceEnd && service[dayOfWeek] === '1') {
        activeServices.add(service.service_id);
      }
    });

    // Apply calendar date exceptions
    calendarDates.forEach(exception => {
      if (exception.date === dateStr) {
        if (exception.exception_type === '1') {
          activeServices.add(exception.service_id);
        } else if (exception.exception_type === '2') {
          activeServices.delete(exception.service_id);
        }
      }
    });

    servicesByDate.set(format(currentDate, 'yyyy-MM-dd'), Array.from(activeServices));
    currentDate = addDays(currentDate, 1);
  }

  return servicesByDate;
}

/**
 * Build trip stop sequences
 * Returns Map of tripId -> ordered array of stops with station info
 * Also populates stationCoords map
 */
function buildTripStopSequences(trainData, stationMappings) {
  console.log('üîó Building trip stop sequences...');

  const { platformToStation, stationSlugs, stationCoords } = stationMappings;
  const stopsMap = new Map(trainData.stops.map(stop => [stop.stop_id, stop]));

  // Build stop sequence for each trip at PLATFORM level
  const tripPlatformSequences = new Map();

  trainData.stopTimes.forEach(st => {
    if (!tripPlatformSequences.has(st.trip_id)) {
      tripPlatformSequences.set(st.trip_id, []);
    }

    tripPlatformSequences.get(st.trip_id).push({
      stopId: st.stop_id,
      sequence: parseInt(st.stop_sequence || '0'),
      arrival: st.arrival_time,
      departure: st.departure_time
    });
  });

  // Sort each trip's stops by sequence
  for (const [tripId, stops] of tripPlatformSequences) {
    stops.sort((a, b) => a.sequence - b.sequence);
  }

  // Convert platform sequences to station sequences
  const tripStationSequences = new Map();

  for (const [tripId, platformStops] of tripPlatformSequences) {
    const stationSequence = [];
    const seenStations = new Set();

    platformStops.forEach(platformStop => {
      const stationName = platformToStation.get(platformStop.stopId);

      if (stationName && !seenStations.has(stationName)) {
        const stopDetails = stopsMap.get(platformStop.stopId);

        // Store coordinates for this station (first time we see it)
        if (!stationCoords.has(stationName) && stopDetails) {
          stationCoords.set(stationName, {
            lat: parseFloat(stopDetails.stop_lat || '0'),
            lng: parseFloat(stopDetails.stop_lon || '0')
          });
        }

        stationSequence.push({
          station: stationName,
          slug: stationSlugs.get(stationName),
          platformId: platformStop.stopId,
          platform: stopDetails?.platform_code || null,
          platformName: stopDetails?.stop_name || 'Unknown',
          arrival: platformStop.arrival,
          departure: platformStop.departure,
          sequence: platformStop.sequence
        });

        seenStations.add(stationName);
      }
    });

    if (stationSequence.length >= 2) {
      tripStationSequences.set(tripId, stationSequence);
    }
  }

  console.log(`‚úÖ Built ${tripStationSequences.size} trip sequences`);

  return tripStationSequences;
}

/**
 * Generate pattern ID from route, origin, destination, and stop sequence
 */
function generatePatternId(routeId, originSlug, destSlug, intermediateStops) {
  // Base pattern ID
  const baseId = `${routeId}-${originSlug}-${destSlug}`;

  // If no intermediate stops, return base ID
  if (intermediateStops.length === 0) {
    return baseId;
  }

  // Create hash of stop sequence for uniqueness
  const stopSequence = intermediateStops.map(s => s.station).join('-');
  const hash = crypto.createHash('md5').update(stopSequence).digest('hex').substring(0, 6);

  return `${baseId}-${hash}`;
}

/**
 * Generate route data with two-tier structure:
 * TIER 1: Station schedules with patternId references
 * TIER 2: Pattern collection for separate file generation
 */
async function generateRouteData(trainData, stationMappings, tripStopSequences) {
  console.log('üîÑ Generating two-tier route data...');

  const startDate = startOfDay(new Date());
  const endDate = addDays(startDate, DAYS_TO_PROCESS);

  const { platformToStation, stationSlugs, stationPlatforms, stationCoords } = stationMappings;

  // Get active services per date
  const servicesByDate = getActiveServices(
    trainData.calendar,
    trainData.calendarDates,
    startDate,
    endDate
  );

  console.log(`  Processing ${servicesByDate.size} dates`);

  // Create maps for quick lookup
  const stopsMap = new Map(trainData.stops.map(stop => [stop.stop_id, stop]));
  const routesMap = new Map(trainData.routes.map(route => [route.route_id, route]));
  const tripsMap = new Map(trainData.trips.map(trip => [trip.trip_id, trip]));

  // TIER 1: Station route data
  const routeData = new Map();

  // TIER 2: Pattern collection (grouped by origin station)
  const patternsByOrigin = new Map(); // originSlug -> Map<patternId, pattern>

  let processedTrips = 0;

  // Process each date
  for (const [dateStr, activeServices] of servicesByDate) {
    const activeServiceSet = new Set(activeServices);

    // Process each trip
    for (const [tripId, stationSequence] of tripStopSequences) {
      const trip = tripsMap.get(tripId);

      // Skip if service not active on this date
      if (!trip || !activeServiceSet.has(trip.service_id)) {
        continue;
      }

      const route = routesMap.get(trip.route_id);

      // For each origin station in the trip
      stationSequence.forEach((originStop, originIndex) => {
        const originSlug = originStop.slug;

        // Initialize origin if needed
        if (!routeData.has(originSlug)) {
          const coords = stationCoords.get(originStop.station) || { lat: 0, lng: 0 };

          routeData.set(originSlug, {
            station: {
              name: originStop.station,
              slug: originSlug,
              allPlatforms: stationPlatforms.get(originStop.station),
              lat: coords.lat,
              lng: coords.lng
            },
            routes: new Map()
          });
        }

        const originData = routeData.get(originSlug);

        // For each destination AFTER origin in sequence
        stationSequence.slice(originIndex + 1).forEach((destStop, relativeIndex) => {
          const destSlug = destStop.slug;
          const destIndex = originIndex + relativeIndex + 1;

          // Initialize destination if needed
          if (!originData.routes.has(destSlug)) {
            const destCoords = stationCoords.get(destStop.station) || { lat: 0, lng: 0 };

            originData.routes.set(destSlug, {
              destination: {
                name: destStop.station,
                slug: destSlug,
                allPlatforms: stationPlatforms.get(destStop.station),
                lat: destCoords.lat,
                lng: destCoords.lng
              },
              schedules: new Map()
            });
          }

          const destData = originData.routes.get(destSlug);

          // Initialize date if needed
          if (!destData.schedules.has(dateStr)) {
            destData.schedules.set(dateStr, []);
          }

          // Build intermediate stops (stations between origin and destination)
          const intermediateStops = stationSequence.slice(originIndex + 1, destIndex);

          // Generate pattern ID
          const patternId = generatePatternId(
            trip.route_id,
            originSlug,
            destSlug,
            intermediateStops
          );

          // Initialize origin's pattern collection if needed
          if (!patternsByOrigin.has(originSlug)) {
            patternsByOrigin.set(originSlug, new Map());
          }

          const originPatterns = patternsByOrigin.get(originSlug);

          // Collect pattern if not already seen for this origin
          if (!originPatterns.has(patternId)) {
            originPatterns.set(patternId, {
              patternId,
              routeId: trip.route_id,
              routeName: route?.route_short_name || route?.route_long_name || 'Unknown',
              origin: originSlug,
              destination: destSlug,
              stops: intermediateStops.map(stop => ({
                station: stop.slug,
                stationName: stop.station,
                platformId: stop.platformId,
                platform: stop.platform,
                platformName: stop.platformName
              })),
              tripCount: 0
            });
          }

          // Increment trip count for this pattern
          originPatterns.get(patternId).tripCount++;

          // Create compact stopTimes array (just times, parallel to pattern.stops)
          const stopTimes = intermediateStops.map(stop => ({
            arrival: stop.arrival,
            departure: stop.departure
          }));

          // Add trip to this date's schedule (TIER 1 - without intermediate stop details)
          destData.schedules.get(dateStr).push({
            tripId: trip.trip_id,
            routeId: trip.route_id,
            routeName: route?.route_short_name || route?.route_long_name || 'Unknown',
            headsign: trip.trip_headsign || '',

            departure: {
              time: originStop.departure,
              platform: originStop.platform,
              platformId: originStop.platformId,
              platformName: originStop.platformName
            },

            arrival: {
              time: destStop.arrival,
              platform: destStop.platform,
              platformId: destStop.platformId,
              platformName: destStop.platformName
            },

            patternId: patternId,
            stopTimes: stopTimes,

            serviceId: trip.service_id
          });
        });
      });

      processedTrips++;
      if (processedTrips % 1000 === 0) {
        console.log(`  Processed ${processedTrips} trips...`);
      }
    }
  }

  // Calculate total unique patterns across all origins
  let totalPatterns = 0;
  for (const [originSlug, originPatterns] of patternsByOrigin) {
    totalPatterns += originPatterns.size;
  }

  console.log(`‚úÖ Processed ${processedTrips} trip instances across ${servicesByDate.size} dates`);
  console.log(`‚úÖ Generated data for ${routeData.size} origin stations`);
  console.log(`‚úÖ Identified ${totalPatterns} unique trip patterns across all origins`);

  return { routeData, patternsByOrigin };
}

/**
 * Convert route data to JSON-serializable format
 */
function serializeRouteData(routeData) {
  console.log('üì¶ Serializing station files...');

  const serialized = new Map();

  for (const [originSlug, originData] of routeData) {
    const routes = {};

    for (const [destSlug, destData] of originData.routes) {
      const schedules = {};

      for (const [date, trips] of destData.schedules) {
        // Sort trips by departure time
        schedules[date] = trips.sort((a, b) =>
          a.departure.time.localeCompare(b.departure.time)
        );
      }

      routes[destSlug] = {
        destination: destData.destination,
        schedules: schedules
      };
    }

    serialized.set(originSlug, {
      station: originData.station,
      routes: routes
    });
  }

  console.log(`‚úÖ Serialized ${serialized.size} station files`);

  return serialized;
}

/**
 * Save station files locally (TIER 1 - only when not in GitHub Actions)
 */
async function saveStationFilesLocally(stationFiles) {
  if (process.env.GITHUB_ACTIONS) {
    console.log('‚è≠Ô∏è  Skipping local station file save (running in GitHub Actions)');
    return;
  }

  console.log('üíæ Saving station files locally...');

  const outputDir = path.join(__dirname, 'output', 'train-stations-v6');
  await fs.mkdir(outputDir, { recursive: true });

  let saved = 0;
  let totalTrips = 0;

  for (const [originSlug, stationData] of stationFiles) {
    const tripCount = Object.values(stationData.routes)
      .reduce((sum, route) => {
        const dateTrips = Object.values(route.schedules)
          .reduce((dateSum, trips) => dateSum + trips.length, 0);
        return sum + dateTrips;
      }, 0);

    if (tripCount === 0) continue;

    const filename = `train-station-${originSlug}.json`;
    const filepath = path.join(outputDir, filename);

    const fileData = {
      station: stationData.station,
      totalRoutes: Object.keys(stationData.routes).length,
      routes: stationData.routes,
      generated: new Date().toISOString(),
      version: '6.0'
    };

    await fs.writeFile(filepath, JSON.stringify(fileData, null, 2));

    saved++;
    totalTrips += tripCount;

    if (saved % 20 === 0) {
      console.log(`  üìù Saved ${saved} station files...`);
    }
  }

  console.log(`‚úÖ Saved ${saved} station files locally to ${outputDir}`);
  console.log(`   Total trips: ${totalTrips}`);
}

/**
 * Save pattern files locally (TIER 2 - one file per origin station)
 */
async function savePatternFilesLocally(patternsByOrigin) {
  if (process.env.GITHUB_ACTIONS) {
    console.log('‚è≠Ô∏è  Skipping local pattern file save (running in GitHub Actions)');
    return;
  }

  console.log('üíæ Saving pattern files locally...');

  const outputDir = path.join(__dirname, 'output', 'train-patterns-v6');
  await fs.mkdir(outputDir, { recursive: true });

  let saved = 0;
  let totalPatterns = 0;

  for (const [originSlug, originPatterns] of patternsByOrigin) {
    const filename = `train-patterns-${originSlug}.json`;
    const filepath = path.join(outputDir, filename);

    // Convert Map to object for JSON serialization
    const patternsObj = {};
    for (const [patternId, patternData] of originPatterns) {
      patternsObj[patternId] = {
        patternId: patternData.patternId,
        routeId: patternData.routeId,
        routeName: patternData.routeName,
        destination: patternData.destination,
        stops: patternData.stops,
        tripCount: patternData.tripCount
      };
    }

    const fileData = {
      origin: originSlug,
      totalPatterns: originPatterns.size,
      patterns: patternsObj,
      generated: new Date().toISOString(),
      version: '6.0'
    };

    await fs.writeFile(filepath, JSON.stringify(fileData, null, 2));

    saved++;
    totalPatterns += originPatterns.size;

    if (saved % 20 === 0) {
      console.log(`  üìù Saved ${saved} pattern files...`);
    }
  }

  console.log(`‚úÖ Saved ${saved} pattern files locally to ${outputDir}`);
  console.log(`   Total patterns: ${totalPatterns}`);
}

/**
 * Delete existing train files from Blob Storage
 */
async function deleteExistingFiles() {
  console.log('üóëÔ∏è  Deleting existing train files...');

  let deleted = 0;
  let cursor;

  try {
    do {
      const result = await list({ cursor });

      for (const blob of result.blobs) {
        if ((blob.pathname.startsWith('train-station-') || blob.pathname.startsWith('train-patterns-'))
            && blob.pathname.endsWith('.json')) {
          await del(blob.url);
          deleted++;
        }
      }

      cursor = result.hasMore ? result.cursor : undefined;
    } while (cursor);

    console.log(`‚úÖ Deleted ${deleted} existing files`);
  } catch (error) {
    console.warn('‚ö†Ô∏è  Error deleting files:', error.message);
  }
}

/**
 * Upload station files to Vercel Blob Storage (TIER 1)
 */
async function uploadStationFiles(stationFiles) {
  console.log('‚òÅÔ∏è  Uploading station files to Vercel Blob...');

  let uploaded = 0;
  let totalTrips = 0;

  for (const [originSlug, stationData] of stationFiles) {
    const tripCount = Object.values(stationData.routes)
      .reduce((sum, route) => {
        const dateTrips = Object.values(route.schedules)
          .reduce((dateSum, trips) => dateSum + trips.length, 0);
        return sum + dateTrips;
      }, 0);

    if (tripCount === 0) {
      console.log(`  ‚è≠Ô∏è  Skipping ${originSlug} (no trips)`);
      continue;
    }

    const filename = `train-station-${originSlug}.json`;

    const fileData = {
      station: stationData.station,
      totalRoutes: Object.keys(stationData.routes).length,
      routes: stationData.routes,
      generated: new Date().toISOString(),
      version: '6.0'
    };

    await put(filename, JSON.stringify(fileData), {
      access: 'public',
      addRandomSuffix: false,
      contentType: 'application/json'
    });

    uploaded++;
    totalTrips += tripCount;

    console.log(`  ‚úÖ Uploaded ${filename} (${Object.keys(stationData.routes).length} routes, ${tripCount} trips)`);
  }

  console.log(`\n‚úÖ Station upload complete: ${uploaded} files, ${totalTrips} total trips`);
}

/**
 * Upload pattern files to Vercel Blob Storage (TIER 2 - one file per origin station)
 */
async function uploadPatternFiles(patternsByOrigin) {
  console.log('‚òÅÔ∏è  Uploading pattern files to Vercel Blob...');

  let uploaded = 0;
  let totalPatterns = 0;

  for (const [originSlug, originPatterns] of patternsByOrigin) {
    const filename = `train-patterns-${originSlug}.json`;

    // Convert Map to object for JSON serialization
    const patternsObj = {};
    for (const [patternId, patternData] of originPatterns) {
      patternsObj[patternId] = {
        patternId: patternData.patternId,
        routeId: patternData.routeId,
        routeName: patternData.routeName,
        destination: patternData.destination,
        stops: patternData.stops,
        tripCount: patternData.tripCount
      };
    }

    const fileData = {
      origin: originSlug,
      totalPatterns: originPatterns.size,
      patterns: patternsObj,
      generated: new Date().toISOString(),
      version: '6.0'
    };

    await put(filename, JSON.stringify(fileData), {
      access: 'public',
      addRandomSuffix: false,
      contentType: 'application/json'
    });

    uploaded++;
    totalPatterns += originPatterns.size;

    console.log(`  ‚úÖ Uploaded ${filename} (${originPatterns.size} patterns)`);
  }

  console.log(`\n‚úÖ Pattern upload complete: ${uploaded} files, ${totalPatterns} total patterns`);
}

/**
 * Main execution
 */
async function main() {
  console.log('\nüöÇ Train Schedule Processor v6.0 - Two-Tiered Architecture\n');

  try {
    // 1. Build station mappings
    const stationMappings = await buildStationMappings();

    // 2. Download and parse GTFS
    const gtfsBuffer = await downloadGTFS();
    const gtfsData = await parseGTFSFiles(gtfsBuffer);

    // 3. Filter train data
    const trainData = filterTrainData(gtfsData);

    // 4. Build trip stop sequences
    const tripStopSequences = buildTripStopSequences(trainData, stationMappings);

    // 5. Generate two-tier route data
    const { routeData, patternsByOrigin } = await generateRouteData(trainData, stationMappings, tripStopSequences);

    // 6. Serialize station data
    const stationFiles = serializeRouteData(routeData);

    // 7. Save files locally (if not in GitHub Actions)
    await saveStationFilesLocally(stationFiles);
    await savePatternFilesLocally(patternsByOrigin);

    // 8. Delete existing files
    await deleteExistingFiles();

    // 9. Upload to Blob
    await uploadStationFiles(stationFiles);
    await uploadPatternFiles(patternsByOrigin);

    // Calculate total patterns
    let totalPatterns = 0;
    for (const [originSlug, originPatterns] of patternsByOrigin) {
      totalPatterns += originPatterns.size;
    }

    console.log('\n‚úÖ Processing complete!\n');
    console.log(`üìä Summary:`);
    console.log(`   Station files: ${stationFiles.size}`);
    console.log(`   Pattern files (grouped by origin): ${patternsByOrigin.size}`);
    console.log(`   Total patterns: ${totalPatterns}`);
  } catch (error) {
    console.error('\n‚ùå Processing failed:', error);
    process.exit(1);
  }
}

main();
